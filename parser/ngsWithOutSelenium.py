import requests
from bs4 import BeautifulSoup
import re
from .baseParser import BaseParser
from models import NewsItem


class NGSFastParser(BaseParser):
    def __init__(self):
        super().__init__("–ù–ì–°")
        self.url = "https://ngs.ru/text/"

    def parse(self):
        print("üöÄ –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ NGS...")

        try:
            response = self.session.get(self.url, timeout=10)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')

            news_list = []

            # –ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ä–∞–∑–Ω—ã–º –≤–æ–∑–º–æ–∂–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
            selectors = [
                'div[class*="wrap"]',
                'article',
                '[data-news-item]',
                '.news-item'
            ]

            for selector in selectors:
                news_items = soup.select(selector)
                if news_items:
                    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º '{selector}': {len(news_items)}")

                    for item in news_items[:15]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                        try:
                            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫—É
                            title_elem = item.find('a', href=re.compile(r'/news/'))
                            if not title_elem:
                                continue

                            title = title_elem.get_text(strip=True)
                            link = title_elem.get('href', '')

                            if not title or len(title) < 10:
                                continue

                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Å—ã–ª–∫—É
                            if link and not link.startswith('http'):
                                link = 'https://ngs.ru' + link if link.startswith('/') else f'https://ngs.ru/{link}'

                            # –ò—â–µ–º –¥–∞—Ç—É
                            date = "–°–µ–≥–æ–¥–Ω—è"
                            date_elem = item.find(['time', 'span'], class_=re.compile(r'time|date'))
                            if date_elem:
                                date = date_elem.get_text(strip=True)

                            news_item = NewsItem(
                                title=title,
                                link=link,
                                date=date,
                                source=self.source_name
                            )

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                            if not any(n.link == link for n in news_list):
                                news_list.append(news_item)
                                print(f"‚úÖ {title[:60]}...")

                        except Exception as e:
                            continue

                    if news_list:
                        break

            print(f"üéØ NGS: –Ω–∞–π–¥–µ–Ω–æ {len(news_list)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
            return news_list

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ NGS: {e}")
            return []